# LLM Provider Configuration
# API key for your general LLM provider (e.g., OpenAI, Anthropic, etc.)
GENERAL_MY_LLM_PROVIDER_KEY=your_llm_provider_api_key_here

# Model Configuration
# The name of the LLM model to use for inference (e.g., llama3.1:8b, gpt-4, etc.)
MODEL_NAME=llama3.1:8b

# Google API Configuration
# API key for Google services (e.g., Gemini API, Google Cloud services)
GOOGLE_API_KEY=your_google_api_key_here

# Alternative Model Configuration
# API key or model name for testing with Gemma 3 model (4b variant)
AGENT_TEST_GEMMA=gemma3:4b

# Server Configuration
# Port on which the application server will listen
PORT=3000

# Database Configuration
# PostgreSQL connection string: postgres://username:password@host:port/database
DATABASE_URL=postgres://postgres:password@localhost:5432/postgres

# Embedding Model Configuration
# The embedding model to use for vector embeddings (e.g., embeddinggemma:300m)
EMBEDDING_MODEL=embeddinggemma:300m

# File Ingestion Configuration
# Absolute path to the PDF file for manual ingestion during development/testing
MANUAL_INGESTION_PATH=C:\path\to\your\pdf\file.pdf
